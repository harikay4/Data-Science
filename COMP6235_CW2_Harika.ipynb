{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 2: Data Processing\n",
    "\n",
    "## Task 1\n",
    "This coursework will assess your understanding of using NoSQL to store and retrieve data.  You will perform operations on data from the Enron email dataset in a MongoDB database, and write a report detailing the suitability of different types of databases for data science applications.  You will be required to run code to answer the given questions in the Jupyter notebook provided, and write a report describing alternative approaches to using MongoDB.\n",
    "\n",
    "Download the JSON version of the Enron data (using the “Download as zip” to download the data file from http://edshare.soton.ac.uk/19548/, the file is about 380MB) and import into a collection called messages in a database called enron.  You do not need to set up any authentication.  In the Jupyter notebook provided, perform the following tasks, using the Python PyMongo library.\n",
    "\n",
    "Answers should be efficient in terms of speed.  Answers which are less efficient will not get full marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)\n",
    "Write a function which returns a MongoDB connection object to the \"messages\" collection. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_collection",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_collection():\n",
    "    \"\"\"\n",
    "    Connects to the server, and returns a collection object\n",
    "    of the `messages` collection in the `enron` database\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    client = MongoClient('mongodb://localhost:27017')\n",
    "    db = client.enron\n",
    "\n",
    "    return db.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)\n",
    "\n",
    "Write a function which returns the amount of emails in the messages collection in total. [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_amount_of_messages",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_amount_of_messages(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the amount of documents in the collection\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    #When the data is too big, collection.estimated_document_count() gives rough estmation of the count \n",
    "    # and returns the results faster as it uses metdata\n",
    "    return collection.count_documents({})\n",
    "    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "messages = get_collection()\n",
    "x =get_amount_of_messages(messages)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) \n",
    "\n",
    "Write a function which returns each person who was BCCed on an email.  Include each person only once, and display only their name according to the X-To header. [4 points] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_bcced_people",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_bcced_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the names of the people who have received an email by BCC\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    bcc= collection.distinct(\"headers.X-bcc\", {'headers.X-bcc': {'$nin': [None, '']}})\n",
    "    #clean the data\n",
    "    lis = []\n",
    "    for i in bcc:\n",
    "        ind = i.find(\"<\")\n",
    "        y=i[0:ind].replace(\"'\", \"\").strip() \n",
    "        lis.append(y)\n",
    "    #if any more duplicates after cleaning the data? => Ans: Yes, get the Set from the list(30 to 29)\n",
    "    bccSet = set(lis)\n",
    "    return bccSet\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'Apollo, Beth',\n",
      "     u'Barry, Patrick',\n",
      "     u'Beck, Sally',\n",
      "     u'Beth Apollo',\n",
      "     u'Carr, James',\n",
      "     u'Causey, Richard',\n",
      "     u'Choate, Heather',\n",
      "     u'Davis, Dana',\n",
      "     u'De La Paz, Janet',\n",
      "     u'Denny, Jennifer',\n",
      "     u'Gilbert-smith, Doug',\n",
      "     u'Greg Piper',\n",
      "     u'Lokey, Teb',\n",
      "     u'Ogenyi, Gloria',\n",
      "     u'Patti Thompson',\n",
      "     u'Piper, Greg',\n",
      "     u'Ratliff, Dale',\n",
      "     u'Richard Shapiro',\n",
      "     u'Robert Superty',\n",
      "     u'Robertson, Audrey',\n",
      "     u'Shapiro, Richard',\n",
      "     u'Storey, Geoff',\n",
      "     u'Twiggs, Thane',\n",
      "     u'Villarreal, Alex',\n",
      "     u'Wehring, Linda',\n",
      "     u'Westbrook, Cherylene R.',\n",
      "     u'cameron@perfect.com',\n",
      "     u'david.beck@houston.rr.com',\n",
      "     u'ddavissprint20@earthlink.net'])\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "pprint(get_bcced_people(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)\n",
    "\n",
    "Write a function with parameter subject, which gets all emails in a thread with that parameter, and orders them by date (ascending). “An email thread is an email message that includes a running list of all the succeeding replies starting with the original email.”, check for detail descriptions at https://www.techopedia.com/definition/1503/email-thread [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_in_thread",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_emails_in_thread(collection, subject):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails in the thread with that subject\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE  \n",
    "    sort = [('headers.Date', pymongo.ASCENDING)]\n",
    "    filter = {\"headers.Subject\": {\"$regex\": subject}}\n",
    "    return list(messages.find(filter, sort=sort))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': ObjectId('4f16fc98d1e2d3237100435a'),\n",
      "  u'body': u'http://www.telski.com/tandp/extras/photo_of_day/index.html',\n",
      "  u'filename': u'76.',\n",
      "  u'headers': {u'Content-Transfer-Encoding': u'7bit',\n",
      "               u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "               u'Date': u'Tue, 14 Nov 2000 07:09:00 -0800 (PST)',\n",
      "               u'From': u'eric.bass@enron.com',\n",
      "               u'Message-ID': u'<27972472.1075854684357.JavaMail.evans@thyme>',\n",
      "               u'Mime-Version': u'1.0',\n",
      "               u'Subject': u'check it out',\n",
      "               u'To': u'shanna.husser@enron.com, dfranklin@hanovermeasurement.com, \\r\\n\\tjason.bass2@compaq.com, daphneco64@bigplanet.com, \\r\\n\\tlwbthemarine@bigplanet.com',\n",
      "               u'X-FileName': u'ebass.nsf',\n",
      "               u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Sent',\n",
      "               u'X-From': u'Eric Bass',\n",
      "               u'X-Origin': u'Bass-E',\n",
      "               u'X-To': u'Shanna Husser, dfranklin@hanovermeasurement.com, Jason.Bass2@COMPAQ.com, daphneco64@bigplanet.com, lwbthemarine@bigplanet.com',\n",
      "               u'X-bcc': u'',\n",
      "               u'X-cc': u''},\n",
      "  u'mailbox': u'bass-e',\n",
      "  u'subFolder': u'sent'},\n",
      " {u'_id': ObjectId('4f16fc97d1e2d32371003e29'),\n",
      "  u'body': u\"I'm ready, are you?  Did you get my message about Dad?  I don't want you to\\nworry but he will have to be in bed with his leg elevated for a week.  Send\\nhim a nice note, o.k?\\n----- Original Message -----\\nFrom: <Eric.Bass@enron.com>\\nTo: <shusser@enron.com>; <dfranklin@hanovermeasurement.com>;\\n<Jason.Bass2@COMPAQ.com>; <daphneco64@bigplanet.com>;\\n<lwbthemarine@bigplanet.com>\\nSent: Tuesday, November 14, 2000 3:09 PM\\nSubject: check it out\\n\\n\\n> http://www.telski.com/tandp/extras/photo_of_day/index.html\\n>\",\n",
      "  u'filename': u'452.',\n",
      "  u'headers': {u'Bcc': u'jason.bass2@compaq.com',\n",
      "               u'Cc': u'jason.bass2@compaq.com',\n",
      "               u'Content-Transfer-Encoding': u'7bit',\n",
      "               u'Content-Type': u'text/plain; charset=us-ascii',\n",
      "               u'Date': u'Tue, 14 Nov 2000 07:25:00 -0800 (PST)',\n",
      "               u'From': u'daphneco64@bigplanet.com',\n",
      "               u'Message-ID': u'<24383193.1075854677459.JavaMail.evans@thyme>',\n",
      "               u'Mime-Version': u'1.0',\n",
      "               u'Subject': u'Re: check it out',\n",
      "               u'To': u'eric.bass@enron.com',\n",
      "               u'X-FileName': u'ebass.nsf',\n",
      "               u'X-Folder': u'\\\\Eric_Bass_Dec2000\\\\Notes Folders\\\\Notes inbox',\n",
      "               u'X-From': u'\"K. Bass\" <daphneco64@bigplanet.com>',\n",
      "               u'X-Origin': u'Bass-E',\n",
      "               u'X-To': u'Eric.Bass@enron.com',\n",
      "               u'X-bcc': u'',\n",
      "               u'X-cc': u'\"Bass, Jason\" <Jason.Bass2@COMPAQ.com>'},\n",
      "  u'mailbox': u'bass-e',\n",
      "  u'subFolder': u'notes_inbox'}]\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "pprint(get_emails_in_thread(messages, \"check it out\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5)\n",
    "\n",
    "Write a function which returns the percentage of emails sent on a weekend (i.e., Saturday and Sunday) as a `float` between 0 and 1. [6 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_percentage_sent_on_weekend",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_percentage_sent_on_weekend(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return A float between 0 and 1\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "      \n",
    "    filter = {\"$or\": [{\"headers.Date\": {\"$regex\": '^Sat', \"$options\": \"i\"}},{\"headers.Date\": {\"$regex\": '^Sun', \"$options\": \"i\"}}]}\n",
    "    weekend=float(collection.count_documents(filter))\n",
    "    total=float(collection.count_documents({}))\n",
    "    perc  = float(weekend/total)\n",
    "    return perc\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0393\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "pprint(get_percentage_sent_on_weekend(messages))\n",
    "#weekend = 0.0393, weekday = 0.9607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6)\n",
    "\n",
    "Write a function with parameter limit. The function should return for each email account: the number of emails sent, the number of emails received, and the total number of emails (sent and received). Use the following format: [{\"contact\": \"michael.simmons@enron.com\", \"from\": 42, \"to\": 92, \"total\": 134}] and the information contained in the To, From, and Cc headers. Sort the output in descending order by the total number of emails. Use the parameter limit to specify the number of results to be returned. If limit is null, the function should return all results. If limit is higher than null, the function should return the number of results specified as limit. limit cannot take negative values. [10 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "get_emails_between_contacts",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json \n",
    "#Function to get the dictionary with from email along with it's count.\n",
    "def getFromEmails():\n",
    "    groupFrom = { '$group': { '_id': '$headers.From', 'from': {'$sum': 1}}}\n",
    "\n",
    "    fromE = messages.aggregate([groupFrom])\n",
    "    fromEmails ={}\n",
    "    for i in fromE:\n",
    "        email= i[\"_id\"] \n",
    "        value=i[\"from\"] \n",
    "        if email in fromEmails:\n",
    "            fromEmails[email] +=value\n",
    "        else:\n",
    "            fromEmails[email] =value\n",
    "    return fromEmails\n",
    "\n",
    "# Tried to use $split from mongoDB along with butilt-in aggregations like above case \"fromEmails\".\n",
    "#This version is not supporting $split, so writing for loops instead of upgrading the VM\n",
    "def getToEmails():\n",
    "    toE= messages.find({'headers.To': {'$nin': [None, '']}},projection={\"headers.To\":1, \"_id\":0} ).limit(100)\n",
    "  \n",
    "    #clean the data\n",
    "    toEmails = {}\n",
    "    for i in toE:\n",
    "        emails= i[\"headers\"][\"To\"].split(\",\")\n",
    "        for i in emails:\n",
    "            email = i.strip()\n",
    "            if email in toEmails:\n",
    "                toEmails[email] +=1\n",
    "            else:\n",
    "                toEmails[email] =1\n",
    "        \n",
    "    return toEmails\n",
    "    pass\n",
    "\n",
    "#Same as above, but get emails in \"CC\" and respective counts\n",
    "def getCcEmails():\n",
    "    ccE= messages.find({'headers.Cc': {'$nin': [None, '']}},projection={\"headers.Cc\":1, \"_id\":0} ).limit(100)\n",
    "  \n",
    "    #clean the data\n",
    "    ccEmails = {}\n",
    "    for i in ccE:\n",
    "        emails= i[\"headers\"][\"Cc\"].split(\",\")\n",
    "        for i in emails:\n",
    "            email = i.strip()\n",
    "            if email in ccEmails:\n",
    "                ccEmails[email] +=1\n",
    "            else:\n",
    "                ccEmails[email] =1     \n",
    "    return ccEmails\n",
    "    pass\n",
    "\n",
    "#This function merges to 2 dictionary, sum over the values. Merge \"To\" and \"Cc\" email counts and retrun the totals\n",
    "def mergeTwoDict(x,y):\n",
    "    total =y\n",
    "    for key in x:\n",
    "        if key in total:\n",
    "            total[key] +=x[key]\n",
    "        else:\n",
    "            total[key] =x[key]\n",
    "    return total \n",
    "\n",
    "#This function merges the input dictionaries\n",
    "#Merges \"fromEmail\" and \"toEmail\" dictionaries and gets the output list with json objects\n",
    "def mergeFromToDict(x,y):\n",
    "    output =[]\n",
    "    z=set(x.keys()+y.keys())\n",
    "    for key in z:\n",
    "        fromE= x[key] if key in x  else 0\n",
    "        toE=y[key] if key in y  else 0\n",
    "        total = int(fromE+toE)\n",
    "        \n",
    "        output.append({\"contact\": key, \"from\":fromE, \"to\":toE, \"total\":total})\n",
    "    return output \n",
    "\n",
    "def get_emails_between_contacts(collection, limit):\n",
    "    \"\"\"\n",
    "    Shows the communications between contacts\n",
    "    Sort by the descending order of total emails using the To, From, and Cc headers.\n",
    "    :param `collection` A PyMongo collection object    \n",
    "    :param `limit` An integer specifying the amount to display, or\n",
    "    if null will display all outputs\n",
    "    :return A list of objects of the form:\n",
    "    [{\n",
    "        'contact': <<Another email address>>\n",
    "        'from': \n",
    "        'to': \n",
    "        'total': \n",
    "    },{.....}]\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    fromEmail =getFromEmails()\n",
    "    #This would gets emails in \"To\" and also in \"Cc\" with respective counts\n",
    "    toEmail=mergeTwoDict(getToEmails(),getCcEmails())\n",
    "    \n",
    "    output= mergeFromToDict(fromEmail,toEmail)\n",
    "    \n",
    "    #Sort in descending order\n",
    "    output.sort(key=lambda s: s['total'],reverse=True)\n",
    "    \n",
    "    #Limit the results as given by the input parameter\n",
    "    results =output[:limit]\n",
    "    \n",
    "    #Return results in nice Json format as requested\n",
    "    return json.dumps(results, sort_keys=True, indent=4)\n",
    "    \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"contact\": \"jeff.dasovich@enron.com\", \n",
      "        \"from\": 9424, \n",
      "        \"to\": 0, \n",
      "        \"total\": 9424\n",
      "    }, \n",
      "    {\n",
      "        \"contact\": \"sally.beck@enron.com\", \n",
      "        \"from\": 4244, \n",
      "        \"to\": 0, \n",
      "        \"total\": 4244\n",
      "    }, \n",
      "    {\n",
      "        \"contact\": \"david.delainey@enron.com\", \n",
      "        \"from\": 2959, \n",
      "        \"to\": 0, \n",
      "        \"total\": 2959\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "print(get_emails_between_contacts(messages, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7)\n",
    "Write a function to find out the number of senders who were also direct receivers. Direct receiver means the email is sent to the person directly, not via cc or bcc. [4 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_to_people(collection):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return the NUMBER of the people who have sent emails and received emails as direct receivers.\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    fromEmails= messages.distinct(\"headers.From\", {'headers.From': {'$nin': [None, '']}})\n",
    "    toEmails= getToEmails(messages)\n",
    "    results =intersection(fromEmails,toEmails)\n",
    "    return len(results)\n",
    "\n",
    "\n",
    "    pass\n",
    "\n",
    "#Function to get all unique emails in \"To\" list\n",
    "def getToEmails(collection):\n",
    "    toEmail= collection.distinct(\"headers.To\", {'headers.To': {'$nin': [None, '']}})\n",
    "    #clean the data\n",
    "    lis = []\n",
    "    for i in toEmail:\n",
    "        ind = i.find(\"<\")\n",
    "        y=i[0:ind].strip().split(\",\")\n",
    "        for j in y:\n",
    "            lis.append(j.strip())\n",
    "    myset = set(lis)\n",
    "    return lis\n",
    "    pass\n",
    "\n",
    "# Gets the intersection\n",
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2822\n"
     ]
    }
   ],
   "source": [
    "# TESTS\n",
    "pprint(get_from_to_people(messages))\n",
    "# result length =2822\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8)\n",
    "Write a function with parameters start_date and end_date, which returns the number of email messages that have been sent between those specified dates, including start_date and end_date [4 points] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta, datetime, tzinfo\n",
    "def get_emails_between_dates(collection, start_date, end_date):\n",
    "    \"\"\"\n",
    "    :param collection A PyMongo collection object\n",
    "    :return All emails between the specified start_date and end_date\n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE  \n",
    "    #Convert the date into ISO format which is default for mongoDB\n",
    "    #simple mongoDB function, which can't accept the datetime python object format or ISO as the it is retrived as string\n",
    "        #'Fri, 1 Dec 2000 00:03:00 -0800 (PST)'}\n",
    "        \n",
    "    #format=\"%a, %-d %b %Y %H:%M:%S %z %Z\"\n",
    "    #start = start_date.strftime(format)\n",
    "    #end= end_date.strftime(format)\n",
    "    \n",
    "    \n",
    "    filter = {\"$and\": [{\"headers.Date\": { '$gte': start }},{\"headers.Date\": {'$lte':end}}]}\n",
    "    return collection.count_documents(filter)\n",
    "    \n",
    " \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "#Alternate solution so that this function can work with python datetime obects,\n",
    "#but limit on number of records for performance reasons with sort on all items\n",
    "def alternateSol(collection, start_date, end_date):\n",
    "    sort1 = [(\"headers.Date\", pymongo.ASCENDING)]\n",
    "    x =collection.find({},projection={\"headers.Date\":1, \"_id\":0},sort=sort1 ).limit(100)\n",
    "    results =0\n",
    "    for i in x:\n",
    "\n",
    "        y= i['headers']['Date'].split(\",\")[1].strip()\n",
    "        ind= y.find(\"-\")\n",
    "        z= y[:ind].strip()\n",
    "        z= datetime.strptime(z, '%d %b %Y %H:%M:%S')\n",
    "\n",
    "        if z>= start_date and z<=end_date:\n",
    "            results +=1\n",
    "    return results\n",
    "\n",
    "#TESTS\n",
    "datefrom='2000-12-1 00:19:00'\n",
    "dateto='2014-12-1 00:58:00'\n",
    "startdate = datetime.strptime(datefrom, '%Y-%m-%d %H:%M:%S')\n",
    "enddate =  datetime.strptime(dateto, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "emails=alternateSol(messages, startdate, enddate)\n",
    "pprint(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "This task will assess your ability to use the Hadoop Streaming API and MapReduce to process data. For each of the questions below, you are expected to write two python scripts, one for the Map phase and one for the Reduce phase. You are also expected to provide the correct parameters to the `hadoop` command to run the MapReduce process. Write down your answers in the specified cells below.\n",
    "\n",
    "To get started, you need to download and unzip the YouTube dataset (available at http://edshare.soton.ac.uk/19547/) onto the machine where you have Hadoop installed (this should be the virtual machine provided).\n",
    "\n",
    "To help you, `%%writefile` has been added to the top of the cells, automatically writing them to \"mapper.py\" and \"reducer.py\" respectively when the cells are run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) \n",
    "Using Youtube01-Psy.csv, find the hourly interval in which most spam was sent. The output should be in the form of a single key-value pair, where the value is a datetime at the start of the hour with the highest number of spam comments. [9 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python2.7\n",
    "#Answer for mapper.py\n",
    "#aggregation by hour and get the max of it\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def main():\n",
    "    lines = sys.stdin.readlines()\n",
    "\n",
    "    csvreader = csv.reader(lines)\n",
    "    for row in csvreader:\n",
    "\n",
    "        date,spam = row[2], row[4]\n",
    "\n",
    "        if date.startswith(\"20\") and int(spam)==1:\n",
    "            #print(date,spam)\n",
    "            datetime_object = datetime.strptime(date.split(\".\", 1)[0], '%Y-%m-%dT%H:%M:%S')\n",
    "            result=datetime_object.replace(microsecond=0,second=0,minute=0)\n",
    "            out=result.strftime('%Y-%m-%dT%H:%M:%S'),int(spam)\n",
    "            print('%s\\t%s' % (result.strftime('%Y-%m-%dT%H:%M:%S'),int(spam)))\n",
    "            #Convert date to String => date.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#STEPS:\n",
    "#select DATE, CLASS and pass to reducer, filter for DATE where it is not real DATE format and send \n",
    "#send only date rounded to start top of the HOUR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python2.7\n",
    "# REDUCER\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "# Keep simple example in for now, switch to stdin later\n",
    "def main():\n",
    "    input_pairs = sys.stdin.readlines()\n",
    "    output ={}\n",
    "\n",
    "    for word in input_pairs:\n",
    "        word1=word.strip(\"()\").strip(\" \").replace(\"'\", \"\").replace(\")\", \"\").replace(\"(\", \"\").split(\"\\t\")\n",
    "        (date,count) =(word1[0],int(word1[1].strip(\" \")))\n",
    "\n",
    "        if date in output:\n",
    "            output[date] +=count\n",
    "        else:\n",
    "            output[date] =count\n",
    "    max_=1\n",
    "    result1=\"\"\n",
    "    result2=\"\"\n",
    "    for key, value in output.items():\n",
    "\n",
    "        if value> max_:\n",
    "            max_=value\n",
    "            result2=result1\n",
    "            result1=key\n",
    "\n",
    "    print('%s\\t%s' % (\"hour_with_most_spam\" ,result1))\n",
    "    print('%s\\t%s' % (\"hour_with_next_most_spam\", result2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#STEPS:\n",
    "# Sum over the count\n",
    "# Return only tab sepearated string with the resulted DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "19/12/14 16:54:03 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/home/comp6235/Notebooks/CW2/output': No such file or directory\n",
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "19/12/14 16:54:04 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "19/12/14 16:54:04 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/12/14 16:54:04 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "19/12/14 16:54:04 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "19/12/14 16:54:04 INFO mapreduce.JobSubmitter: Cleaning up the staging area file:/tmp/hadoop-comp6235/mapred/staging/comp6235123611279/.staging/job_local123611279_0001\n",
      "19/12/14 16:54:04 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube01-Psy.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube02-KatyPerry.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube03-LMFAO.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube04-Eminem.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube05-Shakira.csv\n",
      "Streaming Command Failed!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Hadoop command to run the map reduce.\n",
    "hadoop fs -rm -r /home/comp6235/Notebooks/CW2/output\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files mapper.py,reducer.py \\\n",
    "-input Youtube01-Psy.csv,Youtube02-KatyPerry.csv,Youtube03-LMFAO.csv,Youtube04-Eminem.csv,Youtube05-Shakira.csv \\\n",
    "-mapper ./mapper.py \\\n",
    "-reducer ./reducer.py \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#hour_with_most_spam\t\"2013-11-10T10:00:00\"\n",
    "\n",
    "#Additional key-value pairs are acceptable, as long as the hour_with_most_spam pair is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) \n",
    "Find all comments associated with a username (the AUTHOR field). Return a JSON array of all comments associated with that username. (This should use the data from all 5 data files: Psy, KatyPerry, LMFAO, Eminem, Shakira) [11 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python2.7\n",
    "#Answer for mapper.py\n",
    "#aggregation by hour and get the max of it\n",
    "import csv\n",
    "import sys\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def main():\n",
    "   #Since it is not clear author field can be provided as input parameter, implementing the respective functionality\n",
    "#Remove the filter to get the all list, if empty parameter also it should give all list\n",
    "    #username=os.environ[\"user\"]\n",
    "    lines = sys.stdin.readlines()\n",
    "   \n",
    "    csvreader = csv.reader(lines)\n",
    "    for row in csvreader:\n",
    "        author,comment = row[1], row[3]\n",
    "        if author and comment:\n",
    "            out=author, comment\n",
    "            print '%s\\t%s'% (author ,comment)\n",
    "\n",
    "                \n",
    "            \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#STEPS:\n",
    "#select AUTHOR,COMMENT_ID filter for AUTHOR receiving from input parameter\n",
    "#send only COMMENT_ID, CONTENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python2.7\n",
    "# REDUCER\n",
    "\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "# Keep simple example in for now, switch to stdin later\n",
    "def main():\n",
    "    input_pairs = sys.stdin.readlines()\n",
    "\n",
    "    output ={}\n",
    "\n",
    "    for word in input_pairs:\n",
    "        word1=word.split(\"\\t\")\n",
    "        (author,comment) =(word1[0].strip(),word1[1].strip())\n",
    "        \n",
    "\n",
    "        if author in output:\n",
    "            output[author].append(comment)\n",
    "        else:\n",
    "            lis=[]\n",
    "            output[author] =[comment]\n",
    "    \n",
    "\n",
    "        print('%s\\t%s' % (author ,output[author]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "#STEPS:\n",
    "# Sum over the count\n",
    "# Return only tab sepearated string with the resulted DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "19/12/14 16:52:28 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/home/comp6235/Notebooks/CW2/output': No such file or directory\n",
      "OpenJDK Server VM warning: You have loaded library /opt/hadoop-2.8.5/lib/native/libhadoop.so.1.0.0 which might have disabled stack guard. The VM will try to fix the stack guard now.\n",
      "It's highly recommended that you fix the library with 'execstack -c <libfile>', or link it with '-z noexecstack'.\n",
      "19/12/14 16:52:29 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "19/12/14 16:52:30 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/12/14 16:52:30 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "19/12/14 16:52:30 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "19/12/14 16:52:30 INFO mapreduce.JobSubmitter: Cleaning up the staging area file:/tmp/hadoop-comp6235/mapred/staging/comp62351814280996/.staging/job_local1814280996_0001\n",
      "19/12/14 16:52:30 ERROR streaming.StreamJob: Error Launching job : Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube01-Psy.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube02-KatyPerry.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube03-LMFAO.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube04-Eminem.csv\n",
      "Input path does not exist: file:/home/comp6235/Notebooks/CW2/submission/Youtube05-Shakira.csv\n",
      "Streaming Command Failed!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#Hadoop command to run the map reduce.\n",
    "hadoop fs -rm -r /home/comp6235/Notebooks/CW2/output\n",
    "\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "-files mapper.py,reducer.py \\\n",
    "-input Youtube01-Psy.csv,Youtube02-KatyPerry.csv,Youtube03-LMFAO.csv,Youtube04-Eminem.csv,Youtube05-Shakira.csv \\\n",
    "-mapper mapper.py \\\n",
    "-reducer ./reducer.py \\\n",
    "-output output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expected key-value output format:\n",
    "#John Smith\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]\n",
    "#Jane Doe\t[\"Comment 1\", \"Comment 2\", \"Comment 3\", \"etc.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
